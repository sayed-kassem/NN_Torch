{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOK9t6jXBwN6V1B7lBDFkgm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayed-kassem/NN_Torch/blob/main/Seq2Seq/NMT_ENG_FR_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "OrVzoQIDQF6e"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "  def __init__(self,name):\n",
        "    self.name = name\n",
        "    self.word2index={}\n",
        "    self.word2count={}\n",
        "    self.index2word= {0: \"SOS\", 1:\"EOS\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def addSentence(self, sentence):\n",
        "    for word in sentence.split(' '):\n",
        "      self.addWord(word)\n",
        "\n",
        "  def addWord(self,word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words +=1\n",
        "    else:\n",
        "      self.word2count[word] +=1\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join( c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def normalizeString(s):\n",
        "    #low, trim , remove non-letter characters\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\",s)\n",
        "    s = re.sub(r\"[^a-zA-z!?]+\",r\" \",s)\n",
        "    return s.strip()\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "  print(\"Reading Lines...\")\n",
        "  #Read file and split in to lines\n",
        "  lines = open('data/%s-%s.txt' %(lang1,lang2), encoding='utf-8').read().strip().split('\\n')\n",
        "  #Split every line into pairs and normalize\n",
        "  pairs = [[normalizeString(s) for s in l.split('\\t')] for l  in lines]\n",
        "  #Reverse pairs, make Lang Instances\n",
        "  if reverse:\n",
        "    pairs = [list(reversed(p)) for p in pairs]\n",
        "    input_lang = Lang(lang2)\n",
        "    output_lang = Lang(lang1)\n",
        "  else:\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "  return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "4xTYAzN2QchX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "  return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smLdh_Up3gQZ",
        "outputId": "748aa768-9647-48b0-c27b-e62cd39d1000"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "['je manque d espace dans mon placard', 'i m running out of closet space']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size,dropout_p=0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, batch_first = True)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    output, hidden = self.gru(embedded)\n",
        "    return output, hidden\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(output_size,hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size,batch_first= True)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward (self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "    batch_size = encoder_outputs.size(0)\n",
        "    decoder_input = torch.empty(batch_size,1,dtype=torch.long,device=device).fill_(SOS_token)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_outputs = []\n",
        "\n",
        "    for i in range(MAX_LENGTH):\n",
        "      decoder_output, decoder_hidden = self.forward_step(decoder_input,decoder_hidden)\n",
        "      decoder_outputs.append(decoder_output)\n",
        "\n",
        "      if target_tensor is not None:\n",
        "        decoder_input = target_tensor[:,i].unsqueeze(1)\n",
        "      else:\n",
        "        _, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "      decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "      decoder_outputs = F.log_softmax(decoder_outputs, dim=1)\n",
        "      return decoder_outputs, decoder_hidden, None\n",
        "\n",
        "    def forward_step(self,input, hidden):\n",
        "      output = self.embedding(input)\n",
        "      output= F.relu(output)\n",
        "      output, hidden = self.gru(output,hidden)\n",
        "      output = self.out(output)\n",
        "      return output, hidden"
      ],
      "metadata": {
        "id": "bDwB4-6nOe27"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "Ut0ExPJ2Esxp"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing Training Data"
      ],
      "metadata": {
        "id": "HiQr2QFXhE6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ],
      "metadata": {
        "id": "ye45bzSCOY-e"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "uoPE6ilKklpu"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinute(s):\n",
        "  m = math.floor(s/60)\n",
        "  s-=m*60\n",
        "  return \"%dm %ds\" %(m,s)\n",
        "def timeSince(since, percent):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  es = s/(percent)\n",
        "  rs = es - s\n",
        "  return \"%s (- %s)\" %(asMinute(s), asMinute(rs))\n",
        ""
      ],
      "metadata": {
        "id": "2XaNi7sAlesC"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "W4clZWysxSJC"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "32N7CxPUmlSn"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder,decoder,sentence,input_lang,output_lang):\n",
        "  with torch.no_grad():\n",
        "    input_tensor = tensorFromSentence(input_lang,sentence)\n",
        "\n",
        "    encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "    decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs,encoder_hidden)\n",
        "\n",
        "    _, topi = decoder_outputs.topk(1)\n",
        "    decoded_ids = topi.squeeze()\n",
        "\n",
        "    decoded_words = []\n",
        "    for idx in decoded_ids:\n",
        "      if idx.item() == EOS_token:\n",
        "        decoded_words.append(\"<EOS>\")\n",
        "        break\n",
        "      decoded_words.append(output_lang.index2word[idx.item()])\n",
        "  return decoded_words, decoder_attn\n",
        ""
      ],
      "metadata": {
        "id": "s3vw1LWsx0zw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder,decoder, n=10):\n",
        "  for i in range(n):\n",
        "    pair = random.choice(pairs)\n",
        "    print('>', pair[0])\n",
        "    print('=', pair[1])\n",
        "    output_words, _ = evaluate(encoder,decoder,pair[0], input_lang, output_lang)\n",
        "    output_sentence = ' '.join(output_words)\n",
        "    print('<', output_sentence)\n",
        "    print(' ')\n",
        "\n",
        "\n",
        "hidden_size = 128\n",
        "batch_size =32\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "encoder = EncoderRNN(input_lang.n_words,hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words). to(device)\n",
        "\n",
        "train(train_dataloader,encoder,decoder,100, print_every=10, plot_every=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoJg9m0JyvRa",
        "outputId": "4fea58d5-7ccc-41e8-c874-19672a6ddeca"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "1m 12s (- 10m 49s) (10 10%) 1.0917\n",
            "2m 24s (- 9m 36s) (20 20%) 0.2652\n",
            "3m 36s (- 8m 24s) (30 30%) 0.1009\n",
            "4m 48s (- 7m 12s) (40 40%) 0.0583\n",
            "6m 0s (- 6m 0s) (50 50%) 0.0429\n",
            "7m 12s (- 4m 48s) (60 60%) 0.0359\n",
            "8m 24s (- 3m 36s) (70 70%) 0.0320\n",
            "9m 36s (- 2m 24s) (80 80%) 0.0298\n",
            "10m 48s (- 1m 12s) (90 90%) 0.0280\n",
            "12m 1s (- 0m 0s) (100 100%) 0.0269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPX6kXvuz09-",
        "outputId": "8064febb-c5c4-4d31-e722-9f05867501c1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> elle est plus vieille que lui\n",
            "= she s older than him\n",
            "< she s older than him <EOS>\n",
            " \n",
            "> je suis heureuse pour vous deux\n",
            "= i m happy for you both\n",
            "< i m happy for you both <EOS>\n",
            " \n",
            "> il n est pas aussi grand que son frere\n",
            "= he is not as tall as his brother\n",
            "< he is not as tall as his brother <EOS>\n",
            " \n",
            "> tu trouves toujours des reproches a me faire\n",
            "= you re always finding fault with me\n",
            "< you re always finding fault with me <EOS>\n",
            " \n",
            "> tu es trop faible\n",
            "= you re too weak\n",
            "< you re too weak <EOS>\n",
            " \n",
            "> c est une personne tres sympa\n",
            "= she is a very nice person\n",
            "< she is a very nice person <EOS>\n",
            " \n",
            "> je suis celibataire\n",
            "= i m single\n",
            "< i am single <EOS>\n",
            " \n",
            "> nous allons voyager en voiture\n",
            "= we are going to travel by car\n",
            "< we are going to travel by car <EOS>\n",
            " \n",
            "> vous etes toutes malades\n",
            "= you re all insane\n",
            "< you re all insane <EOS>\n",
            " \n",
            "> je suis heureux d accepter votre invitation\n",
            "= i am glad to accept your invitation\n",
            "< i am glad to accept your invitation <EOS>\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateTestSentence(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "\n",
        "\n",
        "evaluateTestSentence('il n est pas aussi grand que son pere')\n",
        "\n",
        "evaluateTestSentence('je suis trop fatigue pour conduire')\n",
        "\n",
        "evaluateTestSentence('je suis desole si c est une question idiote')\n",
        "\n",
        "evaluateTestSentence('je suis reellement fiere de vous')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCmh2F7i7EaE",
        "outputId": "ac7c2502-9f64-4d14-f192-9ef264aec12f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = il n est pas aussi grand que son pere\n",
            "output = he is not as tall as his father <EOS>\n",
            "input = je suis trop fatigue pour conduire\n",
            "output = i m too tired to drive <EOS>\n",
            "input = je suis desole si c est une question idiote\n",
            "output = i m sorry if this is a stupid question <EOS>\n",
            "input = je suis reellement fiere de vous\n",
            "output = i m really proud of you <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6igMWkvRLH3"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}